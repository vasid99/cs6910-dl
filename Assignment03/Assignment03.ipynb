{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment03_Krish.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3DhFtI8H5AIC",
        "3-NFLIXk51NL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "279b37ff47374f4e9c88648862d24152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0cf5fa952b8e4f8d9e218bfa00111d8c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9cf093c8f1d34a9d82d370df9d347ea2",
              "IPY_MODEL_d539bccbdc394a8ca700ec47601c86ac"
            ]
          }
        },
        "0cf5fa952b8e4f8d9e218bfa00111d8c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cf093c8f1d34a9d82d370df9d347ea2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_c18858c7d199400296d6db37c7e8f432",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.73MB of 1.73MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5adbc19647cf499bb257c3787989fd99"
          }
        },
        "d539bccbdc394a8ca700ec47601c86ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2be4fba53ed14856b3b3c5912dcb3880",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18eade9f98934ddf923b1dca965858e5"
          }
        },
        "c18858c7d199400296d6db37c7e8f432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5adbc19647cf499bb257c3787989fd99": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2be4fba53ed14856b3b3c5912dcb3880": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18eade9f98934ddf923b1dca965858e5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0idENJUy464K"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOuJdDvYDbv8"
      },
      "source": [
        "!pip install -q wandb"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PATZzAYvjFKg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "import datetime\n",
        "tz_ist = datetime.timezone(datetime.timedelta(hours=5, minutes=30))\n",
        "timestr = lambda fmt:datetime.datetime.now(tz=tz_ist).strftime(fmt)\n",
        "\n",
        "import tensorflow as tf\n",
        "ks = tf.keras\n",
        "import wandb"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi5rn-e7m25n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2dee49f5-a0b7-4c83-d5fd-744e4195e8ac"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DhFtI8H5AIC"
      },
      "source": [
        "# Dataset Loading, Characteristic Extraction and Reshaping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3fjeYakm8cl"
      },
      "source": [
        "basepath = \"/content/drive/MyDrive/Sem_8/dl-datasets/dakshina_dataset_v1.0/hi/lexicons\"\n",
        "\n",
        "col_names = ['Dev.','Roman','att.']\n",
        "STARTCHAR = '\\t'\n",
        "ENDCHAR   = '\\n'\n",
        "\n",
        "def read_as_array(path):\n",
        "  data = pd.read_csv(path, sep='\\t', names=col_names).drop_duplicates(subset=\"Dev.\").dropna()\n",
        "  data['Dev.'] = STARTCHAR + data['Dev.'] + ENDCHAR\n",
        "  return np.array(data)[:,:2]\n",
        "\n",
        "train_data = read_as_array(basepath+\"/hi.translit.sampled.train.tsv\")\n",
        "val_data   = read_as_array(basepath+\"/hi.translit.sampled.dev.tsv\")\n",
        "test_data  = read_as_array(basepath+\"/hi.translit.sampled.test.tsv\")"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBFXE2gbv9tw"
      },
      "source": [
        "input_vocab = set()\n",
        "target_vocab = set()\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "  for char in train_data[i,1]:\n",
        "    input_vocab.add(char)\n",
        "  for char in train_data[i,0]:\n",
        "    target_vocab.add(char)\n",
        "\n",
        "input_vocab  = [''] + sorted(list(input_vocab))\n",
        "target_vocab = [''] + sorted(list(target_vocab))\n",
        "\n",
        "len_input_vocab  = len(input_vocab)\n",
        "len_target_vocab = len(target_vocab)\n",
        "\n",
        "input_dict  = dict([ (char, i) for i, char in enumerate(input_vocab)])\n",
        "target_dict = dict([ (char, i) for i, char in enumerate(target_vocab)])\n",
        "\n",
        "max_len_input  = max([ len(word) for data in [train_data[:,1], val_data[:,1], test_data[:,1]] for word in data ])\n",
        "max_len_target = max([ len(word) for data in [train_data[:,0], val_data[:,0], test_data[:,0]] for word in data ])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mi7OBsT8hDA"
      },
      "source": [
        "def str_to_numarray(strs, output_size, charmap):\n",
        "  ret = np.zeros((len(strs), output_size), dtype=\"float32\")\n",
        "  for i, s in enumerate(strs):\n",
        "    for j, ch in enumerate(s): ret[i,j] = charmap[ch]\n",
        "  return ret\n",
        "\n",
        "def vectorize_dataset(data):\n",
        "  # inputs\n",
        "  enc_inp = str_to_numarray(data[:,1], max_len_input, input_dict)\n",
        "  dec_inp = str_to_numarray(data[:,0], max_len_target, target_dict)\n",
        "  \n",
        "  # targets\n",
        "  dec_tgt = np.pad(dec_inp[:,1:],((0,0),(0,1)))\n",
        "  dec_tgt_onehot = np.zeros((data.shape[0], max_len_target, len_target_vocab), dtype=\"float32\")\n",
        "  for i in range(len_target_vocab): dec_tgt_onehot[:,:,i] = dec_tgt[:,:]==i\n",
        "  \n",
        "  return enc_inp, dec_inp, dec_tgt_onehot\n",
        "\n",
        "enc_inp_train, dec_inp_train, dec_tgt_train_onehot = vectorize_dataset(train_data)\n",
        "enc_inp_val,   dec_inp_val,   dec_tgt_val_onehot   = vectorize_dataset(val_data)\n",
        "enc_inp_test,  dec_inp_test,  dec_tgt_test_onehot  = vectorize_dataset(test_data)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-NFLIXk51NL"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYGzxCwa5asf"
      },
      "source": [
        "## Model Handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKGB3v7LqKn0"
      },
      "source": [
        "DEFAULT_NETPARAMS = {\n",
        "    \"embed_size\": 16, \n",
        "    \"latent_dim\": 256, \n",
        "    \"enc_layers\": 1, \n",
        "    \"dec_layers\": 1, \n",
        "    \"recurrent_cell\": \"SimpleRNN\",\n",
        "    \"dec_attention\": False,\n",
        "    \"dropout\": 0, \n",
        "    \"beam_size\": 1, \n",
        "    \"enc_state_dep\": \"first\"\n",
        "}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjhsuXPfDS4m"
      },
      "source": [
        "def fresh_training_model(netparams):\n",
        "  # unpack network parameters\n",
        "  embed_size = netparams[\"embed_size\"]\n",
        "  latent_dim = netparams[\"latent_dim\"]\n",
        "  enc_layers = netparams[\"enc_layers\"]\n",
        "  dec_layers = netparams[\"dec_layers\"]\n",
        "  exec(\"rlexec=ks.layers.\"+netparams[\"recurrent_cell\"]); recurrent_cell = locals()[\"rlexec\"]\n",
        "  dec_attention = netparams[\"dec_attention\"]\n",
        "  dropout    = netparams[\"dropout\"]\n",
        "  enc_state_dep = netparams[\"enc_state_dep\"]\n",
        "\n",
        "  # encoder layers\n",
        "  encoder_input = ks.Input(shape=(None,), name=\"encoder_input\")\n",
        "  encoder_embedding = ks.layers.Embedding(len_input_vocab+1, embed_size, mask_zero=True, name=\"encoder_embedding\")\n",
        "  encoder_rnns = [recurrent_cell(latent_dim, return_sequences=True, return_state=True, dropout=dropout, name=\"encoder_rnn_\"+str(i)) for i in range(1,enc_layers+1)]\n",
        "\n",
        "  # encoder feedforward path\n",
        "  encoder_output = encoder_embedding(encoder_input)\n",
        "  for encoder_rnn in encoder_rnns:\n",
        "    encoder_ret = encoder_rnn(encoder_output)\n",
        "    encoder_output, encoder_state = encoder_ret[0], list(encoder_ret[1:])\n",
        "\n",
        "  # decoder layers\n",
        "  decoder_input = ks.Input(shape=(None,), name=\"decoder_input\")\n",
        "  decoder_embedding = ks.layers.Embedding(len_target_vocab+1, embed_size, mask_zero=True, name=\"decoder_embedding\")\n",
        "  decoder_rnns = [recurrent_cell(latent_dim, return_sequences=True, return_state=True, dropout=dropout, name=\"decoder_rnn_\"+str(i)) for i in range(1,dec_layers+1)]\n",
        "  if dec_attention:\n",
        "    decoder_attention = ks.layers.AdditiveAttention(name=\"decoder_attention\")\n",
        "    decoder_concat    = ks.layers.Concatenate(name=\"decoder_concat\")\n",
        "  decoder_dropout = ks.layers.Dropout(dropout, name=\"decoder_dropout\")\n",
        "  decoder_dense = ks.layers.Dense(len_target_vocab, activation=\"softmax\", name=\"decoder_dense\")\n",
        "\n",
        "  # decoder feedforward path\n",
        "  decoder_rnn_out = decoder_embedding(decoder_input)\n",
        "  for i,decoder_rnn in enumerate(decoder_rnns):\n",
        "    if enc_state_dep=='first':\n",
        "      decoder_state_input = encoder_state if i==0 else None\n",
        "    elif enc_state_dep=='all':\n",
        "      decoder_state_input = encoder_state\n",
        "    else:\n",
        "      decoder_state_input = None\n",
        "    decoder_ret = decoder_rnn(decoder_rnn_out, initial_state=decoder_state_input)\n",
        "    decoder_rnn_out = decoder_ret[0]\n",
        "  if dec_attention:\n",
        "    context_vec, attn_weights = decoder_attention([decoder_rnn_out, encoder_output], return_attention_scores=True)\n",
        "    decoder_dense_input = decoder_concat([decoder_rnn_out, context_vec])\n",
        "  else:\n",
        "    decoder_dense_input = decoder_rnn_out\n",
        "  decoder_dense_input = decoder_dropout(decoder_dense_input, training=True)\n",
        "  decoder_output = decoder_dense(decoder_dense_input)\n",
        "\n",
        "  model = ks.Model([encoder_input, decoder_input], decoder_output, name=\"training_model\")\n",
        "  model.netparams = netparams\n",
        "  return model\n",
        "\n",
        "def gen_enc_dec_models(model):\n",
        "  # get layer from name\n",
        "  layer_idxs = dict([(l.name,i) for i,l in enumerate(model.layers)])\n",
        "  layer_from_name = lambda s: model.layers[layer_idxs[s]]\n",
        "  \n",
        "  # unpack network parameters\n",
        "  netparams  = model.netparams\n",
        "  latent_dim = netparams[\"latent_dim\"]\n",
        "  enc_layers = netparams[\"enc_layers\"]\n",
        "  dec_layers = netparams[\"dec_layers\"]\n",
        "  dec_attention = netparams[\"dec_attention\"]\n",
        "  recurrent_cell_name = netparams[\"recurrent_cell\"]\n",
        "\n",
        "  # reconstructing encoder model\n",
        "    # inputs\n",
        "  encoder_model_input = layer_from_name(\"encoder_input\").input\n",
        "    # outputs\n",
        "  encoder_model_ret = layer_from_name(\"encoder_rnn_\"+str(enc_layers)).output\n",
        "  encoder_model_output, encoder_model_state_output = encoder_model_ret[0], list(encoder_model_ret[1:])\n",
        "    # model reconstruction\n",
        "  encoder_model = ks.Model(\n",
        "    encoder_model_input, \n",
        "    [encoder_model_output, encoder_model_state_output], \n",
        "    name=\"encoder_model\"\n",
        "  )\n",
        "\n",
        "  # reconstructing decoder model\n",
        "    # inputs\n",
        "  decoder_model_input  = layer_from_name(\"decoder_input\").input\n",
        "  decoder_model_encoder_output = ks.Input(shape=(max_len_input,latent_dim,), name=\"decoder_encoder_output\")\n",
        "  decoder_model_state_input  = []\n",
        "    # outputs\n",
        "  decoder_model_output = layer_from_name(\"decoder_embedding\")(decoder_model_input)\n",
        "  decoder_model_state_output = []\n",
        "    # model reconstruction\n",
        "  for dec_layer in range(1,dec_layers+1):\n",
        "    decoder_model_state_input.append(\n",
        "        [ks.Input(shape=(latent_dim,), name=\"decoder_state_h_\"+str(dec_layer)), ks.Input(shape=(latent_dim,), name=\"decoder_state_c_\"+str(dec_layer))] \n",
        "        if recurrent_cell_name==\"LSTM\" else [ks.Input(shape=(latent_dim,), name=\"decoder_state_\"+str(dec_layer))]\n",
        "    )\n",
        "    decoder_ret = layer_from_name(\"decoder_rnn_\"+str(dec_layer))(decoder_model_output, initial_state = decoder_model_state_input[-1])\n",
        "    decoder_model_output, decoder_model_state = decoder_ret[0], list(decoder_ret[1:])\n",
        "    decoder_model_state_output.append(decoder_model_state)\n",
        "    dec_layer += 1\n",
        "  if dec_attention:\n",
        "    decoder_model_context_vec, decoder_model_attention_weights = layer_from_name(\"decoder_attention\")([decoder_model_output, decoder_model_encoder_output], return_attention_scores=True)\n",
        "    decoder_model_output = layer_from_name(\"decoder_concat\")([decoder_model_output, decoder_model_context_vec])\n",
        "  decoder_model_output = layer_from_name(\"decoder_dropout\")(decoder_model_output, training=False)\n",
        "  decoder_model_output = layer_from_name(\"decoder_dense\")(decoder_model_output)\n",
        "  if dec_attention:\n",
        "    decoder_model = ks.Model(\n",
        "      [decoder_model_input, decoder_model_encoder_output, decoder_model_state_input], \n",
        "      [decoder_model_output, decoder_model_state_output, decoder_model_attention_weights], \n",
        "      name=\"decoder_model\"\n",
        "    )\n",
        "  else:\n",
        "    decoder_model = ks.Model(\n",
        "      [decoder_model_input, decoder_model_state_input], \n",
        "      [decoder_model_output, decoder_model_state_output], \n",
        "      name=\"decoder_model\"\n",
        "    )\n",
        "\n",
        "  encoder_model.netparams = netparams\n",
        "  decoder_model.netparams = netparams\n",
        "\n",
        "  return encoder_model, decoder_model"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jUg86VR6CFA"
      },
      "source": [
        "## Decoding Input String"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vdSmTDeI-XB"
      },
      "source": [
        "def decode_sequence(input_seq, models):\n",
        "  # Convert string input to numerical array\n",
        "  encoded_input_seq = str_to_numarray([input_seq], max_len_input, input_dict)\n",
        "\n",
        "  # Unpack testing model and its network parameters\n",
        "  encoder_model, decoder_model = models\n",
        "  netparams = decoder_model.netparams\n",
        "  latent_dim = netparams[\"latent_dim\"]\n",
        "  recurrent_cell_name = netparams[\"recurrent_cell\"]\n",
        "  dec_attention = netparams[\"dec_attention\"]\n",
        "  dec_layers = netparams[\"dec_layers\"]\n",
        "  enc_state_dep = netparams[\"enc_state_dep\"]\n",
        "  \n",
        "  # Run encoder model and create initial state for decoder\n",
        "  encoder_layer_out, encoder_states_out = encoder_model.predict(encoded_input_seq)\n",
        "  default_initial_state = [np.zeros((1,latent_dim))]*(2 if recurrent_cell_name==\"LSTM\" else 1)\n",
        "  if enc_state_dep=='first':\n",
        "    decoder_state = [encoder_states_out] + [default_initial_state]*(dec_layers-1)\n",
        "  elif enc_state_dep=='all':\n",
        "    decoder_state = [encoder_states_out] * dec_layers\n",
        "  else:\n",
        "    decoder_state = [default_initial_state] * dec_layers\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.array(target_dict[STARTCHAR],ndmin=2)\n",
        "\n",
        "  # Sampling loop for a batch of sequences\n",
        "  # (to simplify, here we assume a batch of size 1).\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "  while not stop_condition:\n",
        "    if dec_attention:\n",
        "      output_tokens, decoder_state, attn_weights = decoder_model.predict([target_seq, encoder_layer_out, decoder_state])\n",
        "    else:\n",
        "      output_tokens, decoder_state = decoder_model.predict([target_seq, decoder_state])\n",
        "\n",
        "    # Sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = target_vocab[sampled_token_index]\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    if dec_attention:\n",
        "      # attn_weights: my time to shine!\n",
        "      pass\n",
        "    \n",
        "    # Exit condition: either hit max length\n",
        "    # or find stop character.\n",
        "    if sampled_char == ENDCHAR or len(decoded_sentence) > max_len_target:\n",
        "      stop_condition = True\n",
        "\n",
        "    # Update the target sequence (of length 1).\n",
        "    target_seq[0,0] = sampled_token_index\n",
        "  return decoded_sentence"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TITfjs6n5kh_"
      },
      "source": [
        "# Sample Runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR2_cz6vUimT"
      },
      "source": [
        "## Training a model for a particular network configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OEEPxLutm-Q"
      },
      "source": [
        "# initialize training model\n",
        "netparams = DEFAULT_NETPARAMS.copy()\n",
        "netparams.update({\n",
        "  \"embed_size\": 16, \n",
        "  \"latent_dim\": 256, \n",
        "  \"enc_layers\": 3, \n",
        "  \"dec_layers\": 2, \n",
        "  \"recurrent_cell\": \"LSTM\",\n",
        "  \"dec_attention\": True,\n",
        "  \"dropout\": 0.05, \n",
        "  \"beam_size\": 1, \n",
        "  \"enc_state_dep\": \"first\"\n",
        "})\n",
        "training_model = fresh_training_model(netparams) # ks.models.load_model(savedModelPath)\n",
        "training_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET4ji9GkYz0W"
      },
      "source": [
        "# training parameters\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "# compile training model\n",
        "training_model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Create callbacks\n",
        "wandb=True\n",
        "patience=5\n",
        "\n",
        "callbacks=[ks.callbacks.EarlyStopping(\n",
        "  patience=patience,\n",
        "  restore_best_weights=True\n",
        ")]\n",
        "if wandb:\n",
        "  wandb.init(project=\"Dakshina HI Test 1\")\n",
        "  callbacks.append([wandb.keras.WandbCallback(monitor=\"val_accuracy\")])\n",
        "\n",
        "# train seq2seq model\n",
        "training_model.fit(\n",
        "    [enc_inp_train, dec_inp_train],\n",
        "    dec_tgt_train_onehot,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=( [enc_inp_val, dec_inp_val], dec_tgt_val_onehot ),\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohl7khBRXUTc"
      },
      "source": [
        "training_model.evaluate(x=[enc_inp_test, dec_inp_test], y=dec_tgt_test_onehot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5skFP9OyVWPQ"
      },
      "source": [
        "training_model.save(\"/content/drive/MyDrive/Sem_8/s2s_samplerun.h5\")\n",
        "json.dump(netparams, open(\"/content/drive/MyDrive/Sem_8/s2s_samplerun.json\",'w'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6NseynqUvH1"
      },
      "source": [
        "## Testing trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHwFkyuoIfd7"
      },
      "source": [
        "use_trained_model = False\n",
        "load_timestamp = \"20210506_215919\"\n",
        "\n",
        "if use_trained_model:\n",
        "  test_model = training_model\n",
        "else:\n",
        "  test_model = ks.models.load_model(\"/content/drive/MyDrive/Sem_8/trained-models/s2s_sweep_\"+load_timestamp+\".h5\")\n",
        "  test_model.netparams = json.load(open(\"/content/drive/MyDrive/Sem_8/trained-models/s2s_sweep_\"+load_timestamp+\".json\",'r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VrhZZk4i6rB"
      },
      "source": [
        "test_model.evaluate(x=[enc_inp_test, dec_inp_test], y=dec_tgt_test_onehot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2XkoCqBfiQa"
      },
      "source": [
        "encoder_model, decoder_model = gen_enc_dec_models(test_model)\n",
        "encoder_model.summary()\n",
        "decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNdOBVzwTYM1"
      },
      "source": [
        "print(decode_sequence(\"rani\", [encoder_model, decoder_model]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8_vhwvv7W4y"
      },
      "source": [
        "# Training Sweep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vtz3Qo0Ca7v"
      },
      "source": [
        "sweeplog_path = \"/content/drive/MyDrive/Sem_8/sweep/sweeplog.txt\"\n",
        "savemodel_path = \"/content/drive/MyDrive/Sem_8/sweep/trained-models\"\n",
        "run_sep = '-='*30+'-'\n",
        "\n",
        "!mkdir -p $savemodel_path\n",
        "!touch $sweeplog_path"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOWMrRtOFF8-"
      },
      "source": [
        "def runWandbSweep():\n",
        "  wandb.init(project=\"dakshina_sweep\")\n",
        "  \n",
        "  tcr_wandb_format     = timestr(\"%b %d '%y %H:%M\")\n",
        "  tcr_savemodel_format = timestr(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "  cfg = wandb.config\n",
        "  netparams = DEFAULT_NETPARAMS.copy()\n",
        "  netparams.update({\n",
        "    \"embed_size\": cfg.embedding_size, \n",
        "    \"latent_dim\": cfg.hidden_layer_size,\n",
        "    \"enc_layers\": cfg.num_encoder_layers,\n",
        "    \"dec_layers\": cfg.num_decoder_layers,\n",
        "    \"recurrent_cell\": cfg.a1_recurrent_cell,\n",
        "    \"dec_attention\": cfg.decoder_attention,\n",
        "    \"dropout\": cfg.dropout,\n",
        "    \"enc_state_dep\": cfg.encoder_state_dependencies\n",
        "  })\n",
        "  \n",
        "  log_output = \"Sweep run created on \"+tcr_wandb_format+\" (\"+tcr_savemodel_format+\") with following sweep parameters:\\n\"\n",
        "  for i,k in enumerate(netparams):\n",
        "    log_output += str(i+1)+\". \"+k+\" = \"+str(netparams[k])+'\\n'\n",
        "  log_output += \"\\n\\n\"\n",
        "  open(sweeplog_path,'a').write(log_output)\n",
        "  \n",
        "  model = fresh_training_model(netparams)\n",
        "  model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  \n",
        "  model.fit(\n",
        "      [enc_inp_train, dec_inp_train],\n",
        "      dec_tgt_train_onehot,\n",
        "      batch_size=cfg.batch_size,\n",
        "      epochs=cfg.epochs,\n",
        "      validation_data=( [enc_inp_val, dec_inp_val], dec_tgt_val_onehot ),\n",
        "      callbacks=[\n",
        "                  ks.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "                , wandb.keras.WandbCallback(monitor=\"val_accuracy\")\n",
        "                ]\n",
        "  )\n",
        "\n",
        "  model.save(savemodel_path+\"/s2s_sweep_\"+tcr_savemodel_format+\".h5\")\n",
        "  json.dump(netparams, open(savemodel_path+\"/s2s_sweep_\"+tcr_savemodel_format+\".json\",'w'))\n",
        "  open(sweeplog_path,'a').write(\"Sweep run completed, model saved with timestamp: \"+tcr_savemodel_format+\"\\n\\n\"+run_sep+\"\\n\\n\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71HRcdIeY5uU",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "279b37ff47374f4e9c88648862d24152",
            "0cf5fa952b8e4f8d9e218bfa00111d8c",
            "9cf093c8f1d34a9d82d370df9d347ea2",
            "d539bccbdc394a8ca700ec47601c86ac",
            "c18858c7d199400296d6db37c7e8f432",
            "5adbc19647cf499bb257c3787989fd99",
            "2be4fba53ed14856b3b3c5912dcb3880",
            "18eade9f98934ddf923b1dca965858e5"
          ]
        },
        "outputId": "1cf7ceb2-ec13-4e43-c7c7-9c5aac5004bb"
      },
      "source": [
        "wandbSweepCfg = {\n",
        "  \"name\":\"Dakshina Parameter Grid Sweep (xAttention)\", \n",
        "  \"metric\":{\n",
        "    \"name\":\"val_accuracy\",\n",
        "    \"goal\":\"maximize\"\n",
        "  }, \n",
        "  \"method\": \"grid\", \n",
        "  \"parameters\":{\n",
        "    # network parameters\n",
        "    \"embedding_size\": {\"values\":[128, 256]},\n",
        "    \"hidden_layer_size\": {\"values\":[128, 256]},\n",
        "    \"num_encoder_layers\": {\"values\":[1, 2]},\n",
        "    \"num_decoder_layers\": {\"values\":[1]},\n",
        "    \"a1_recurrent_cell\": {\"values\":[\"GRU\", \"LSTM\", \"SimpleRNN\"]},\n",
        "    \"decoder_attention\": {\"values\":[False]},\n",
        "    \"dropout\": {\"values\":[0.2, 0.4]},\n",
        "    \"encoder_state_dependencies\":{\"values\":[\"first\"]},\n",
        "    \n",
        "    # training parameters\n",
        "    \"epochs\": { \"values\":[30] },\n",
        "    \"batch_size\": { \"values\":[32] }\n",
        "  }\n",
        "}\n",
        "\n",
        "open(sweeplog_path,'a').write(run_sep+\"\\n\\nStarted sweep at \"+timestr(\"%H:%M:%S on %b %d, %Y\")+'\\n\\n')\n",
        "\n",
        "sweepId = wandb.sweep(wandbSweepCfg)#\"vasid99/uncategorized/uklnmska\"\n",
        "wandb.agent(sweepId, function = runWandbSweep)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Create sweep with ID: 3bfqe33h\n",
            "Sweep URL: https://wandb.ai/vasid99/uncategorized/sweeps/3bfqe33h\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 4uv9ll5w with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ta1_recurrent_cell: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_attention: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_state_dependencies: first\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.29<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">scarlet-sweep-1</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/vasid99/uncategorized\" target=\"_blank\">https://wandb.ai/vasid99/uncategorized</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/vasid99/uncategorized/sweeps/3bfqe33h\" target=\"_blank\">https://wandb.ai/vasid99/uncategorized/sweeps/3bfqe33h</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/vasid99/uncategorized/runs/4uv9ll5w\" target=\"_blank\">https://wandb.ai/vasid99/uncategorized/runs/4uv9ll5w</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210507_072211-4uv9ll5w</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "782/782 [==============================] - 20s 16ms/step - loss: 1.0439 - accuracy: 0.3180 - val_loss: 0.7282 - val_accuracy: 0.4542\n",
            "Epoch 2/30\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.7115 - accuracy: 0.4843 - val_loss: 0.5243 - val_accuracy: 0.5896\n",
            "Epoch 3/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.5166 - accuracy: 0.6159 - val_loss: 0.4153 - val_accuracy: 0.6765\n",
            "Epoch 4/30\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3877 - accuracy: 0.7015 - val_loss: 0.3130 - val_accuracy: 0.7509\n",
            "Epoch 5/30\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.3219 - accuracy: 0.7500 - val_loss: 0.2777 - val_accuracy: 0.7758\n",
            "Epoch 6/30\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.2777 - accuracy: 0.7828 - val_loss: 0.2459 - val_accuracy: 0.8040\n",
            "Epoch 7/30\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.2517 - accuracy: 0.8032 - val_loss: 0.2308 - val_accuracy: 0.8145\n",
            "Epoch 8/30\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.2302 - accuracy: 0.8173 - val_loss: 0.2216 - val_accuracy: 0.8191\n",
            "Epoch 9/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.2134 - accuracy: 0.8314 - val_loss: 0.2113 - val_accuracy: 0.8299\n",
            "Epoch 10/30\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.2017 - accuracy: 0.8396 - val_loss: 0.2054 - val_accuracy: 0.8332\n",
            "Epoch 11/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1914 - accuracy: 0.8480 - val_loss: 0.1985 - val_accuracy: 0.8416\n",
            "Epoch 12/30\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.1811 - accuracy: 0.8536 - val_loss: 0.1967 - val_accuracy: 0.8401\n",
            "Epoch 13/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1761 - accuracy: 0.8599 - val_loss: 0.1937 - val_accuracy: 0.8448\n",
            "Epoch 14/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1715 - accuracy: 0.8624 - val_loss: 0.1932 - val_accuracy: 0.8462\n",
            "Epoch 15/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1653 - accuracy: 0.8666 - val_loss: 0.1897 - val_accuracy: 0.8489\n",
            "Epoch 16/30\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.1598 - accuracy: 0.8718 - val_loss: 0.1868 - val_accuracy: 0.8514\n",
            "Epoch 17/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1554 - accuracy: 0.8747 - val_loss: 0.1845 - val_accuracy: 0.8550\n",
            "Epoch 18/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1510 - accuracy: 0.8785 - val_loss: 0.1878 - val_accuracy: 0.8492\n",
            "Epoch 19/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1474 - accuracy: 0.8802 - val_loss: 0.1863 - val_accuracy: 0.8515\n",
            "Epoch 20/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1444 - accuracy: 0.8837 - val_loss: 0.1808 - val_accuracy: 0.8595\n",
            "Epoch 21/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1401 - accuracy: 0.8865 - val_loss: 0.1849 - val_accuracy: 0.8552\n",
            "Epoch 22/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1378 - accuracy: 0.8874 - val_loss: 0.1835 - val_accuracy: 0.8561\n",
            "Epoch 23/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1348 - accuracy: 0.8891 - val_loss: 0.1812 - val_accuracy: 0.8582\n",
            "Epoch 24/30\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.1350 - accuracy: 0.8894 - val_loss: 0.1828 - val_accuracy: 0.8597\n",
            "Epoch 25/30\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.1313 - accuracy: 0.8928 - val_loss: 0.1852 - val_accuracy: 0.8570\n",
            "Epoch 26/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1298 - accuracy: 0.8939 - val_loss: 0.1800 - val_accuracy: 0.8601\n",
            "Epoch 27/30\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.1282 - accuracy: 0.8960 - val_loss: 0.1802 - val_accuracy: 0.8616\n",
            "Epoch 28/30\n",
            "782/782 [==============================] - 10s 13ms/step - loss: 0.1244 - accuracy: 0.8988 - val_loss: 0.1814 - val_accuracy: 0.8606\n",
            "Epoch 29/30\n",
            "782/782 [==============================] - 11s 13ms/step - loss: 0.1210 - accuracy: 0.9001 - val_loss: 0.1797 - val_accuracy: 0.8602\n",
            "Epoch 30/30\n",
            "782/782 [==============================] - 11s 14ms/step - loss: 0.1215 - accuracy: 0.8993 - val_loss: 0.1867 - val_accuracy: 0.8555\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 553<br/>Program ended successfully."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "279b37ff47374f4e9c88648862d24152",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 1.72MB of 1.72MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find user logs for this run at: <code>/content/wandb/run-20210507_072211-4uv9ll5w/logs/debug.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Find internal logs for this run at: <code>/content/wandb/run-20210507_072211-4uv9ll5w/logs/debug-internal.log</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run summary:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>29</td></tr><tr><td>loss</td><td>0.12374</td></tr><tr><td>accuracy</td><td>0.89818</td></tr><tr><td>val_loss</td><td>0.18671</td></tr><tr><td>val_accuracy</td><td>0.85545</td></tr><tr><td>_runtime</td><td>328</td></tr><tr><td>_timestamp</td><td>1620372459</td></tr><tr><td>_step</td><td>29</td></tr><tr><td>best_val_accuracy</td><td>0.86157</td></tr><tr><td>best_epoch</td><td>26</td></tr></table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<h3>Run history:</h3><br/><style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    </style><table class=\"wandb\">\n",
              "<tr><td>epoch</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>loss</td><td>█▆▄▃▃▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>accuracy</td><td>▁▃▅▆▆▇▇▇▇▇▇▇▇█████████████████</td></tr><tr><td>val_loss</td><td>█▅▄▃▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▃▅▆▇▇▇▇▇█████████████████████</td></tr><tr><td>_runtime</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_timestamp</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr><tr><td>_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▇▇▇▇███</td></tr></table><br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "Synced 5 W&B file(s), 1 media file(s), 0 artifact file(s) and 1 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    <br/>Synced <strong style=\"color:#cdcd00\">scarlet-sweep-1</strong>: <a href=\"https://wandb.ai/vasid99/uncategorized/runs/4uv9ll5w\" target=\"_blank\">https://wandb.ai/vasid99/uncategorized/runs/4uv9ll5w</a><br/>\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 2mupbz27 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \ta1_recurrent_cell: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdecoder_attention: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropout: 0.2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembedding_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tencoder_state_dependencies: first\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 30\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thidden_layer_size: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_decoder_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_encoder_layers: 2\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                Tracking run with wandb version 0.10.29<br/>\n",
              "                Syncing run <strong style=\"color:#cdcd00\">good-sweep-2</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
              "                Project page: <a href=\"https://wandb.ai/vasid99/uncategorized\" target=\"_blank\">https://wandb.ai/vasid99/uncategorized</a><br/>\n",
              "                Sweep page: <a href=\"https://wandb.ai/vasid99/uncategorized/sweeps/3bfqe33h\" target=\"_blank\">https://wandb.ai/vasid99/uncategorized/sweeps/3bfqe33h</a><br/>\n",
              "Run page: <a href=\"https://wandb.ai/vasid99/uncategorized/runs/2mupbz27\" target=\"_blank\">https://wandb.ai/vasid99/uncategorized/runs/2mupbz27</a><br/>\n",
              "                Run data is saved locally in <code>/content/wandb/run-20210507_072745-2mupbz27</code><br/><br/>\n",
              "            "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "779/782 [============================>.] - ETA: 0s - loss: 1.0142 - accuracy: 0.3348"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}