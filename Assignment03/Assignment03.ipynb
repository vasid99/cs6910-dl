{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Copy of Assignment03_Krish.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "3DhFtI8H5AIC",
        "3-NFLIXk51NL"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0idENJUy464K"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOuJdDvYDbv8"
      },
      "source": [
        "!pip install -q wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PATZzAYvjFKg"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import json\n",
        "import datetime\n",
        "tz_ist = datetime.timezone(datetime.timedelta(hours=5, minutes=30))\n",
        "timestr = lambda fmt:datetime.datetime.now(tz=tz_ist).strftime(fmt)\n",
        "\n",
        "import tensorflow as tf\n",
        "ks = tf.keras\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import wandb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zi5rn-e7m25n"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3DhFtI8H5AIC"
      },
      "source": [
        "# Dataset Loading, Characteristic Extraction and Reshaping"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3fjeYakm8cl"
      },
      "source": [
        "basepath = \"/content/drive/MyDrive/Sem_8/dl-datasets/dakshina_dataset_v1.0/hi/lexicons\"\n",
        "\n",
        "col_names = ['Dev.','Roman','att.']\n",
        "STARTCHAR = '\\t'\n",
        "ENDCHAR   = '\\n'\n",
        "\n",
        "def read_as_array(path):\n",
        "  data = pd.read_csv(path, sep='\\t', names=col_names).drop_duplicates(subset=\"Dev.\").dropna()\n",
        "  data['Dev.'] = STARTCHAR + data['Dev.'] + ENDCHAR\n",
        "  return np.array(data)[:,:2]\n",
        "\n",
        "train_data = read_as_array(basepath+\"/hi.translit.sampled.train.tsv\")\n",
        "val_data   = read_as_array(basepath+\"/hi.translit.sampled.dev.tsv\")\n",
        "test_data  = read_as_array(basepath+\"/hi.translit.sampled.test.tsv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FBFXE2gbv9tw"
      },
      "source": [
        "input_vocab = set()\n",
        "target_vocab = set()\n",
        "\n",
        "for i in range(len(train_data)):\n",
        "  for char in train_data[i,1]:\n",
        "    input_vocab.add(char)\n",
        "  for char in train_data[i,0]:\n",
        "    target_vocab.add(char)\n",
        "\n",
        "input_vocab  = [''] + sorted(list(input_vocab))\n",
        "target_vocab = [''] + sorted(list(target_vocab))\n",
        "\n",
        "len_input_vocab  = len(input_vocab)\n",
        "len_target_vocab = len(target_vocab)\n",
        "\n",
        "input_dict  = dict([ (char, i) for i, char in enumerate(input_vocab)])\n",
        "target_dict = dict([ (char, i) for i, char in enumerate(target_vocab)])\n",
        "\n",
        "max_len_input  = max([ len(word) for data in [train_data[:,1], val_data[:,1], test_data[:,1]] for word in data ])\n",
        "max_len_target = max([ len(word) for data in [train_data[:,0], val_data[:,0], test_data[:,0]] for word in data ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Mi7OBsT8hDA"
      },
      "source": [
        "def str_to_numarray(strs, output_size, charmap):\n",
        "  ret = np.zeros((len(strs), output_size), dtype=\"float32\")\n",
        "  for i, s in enumerate(strs):\n",
        "    for j, ch in enumerate(s): ret[i,j] = charmap[ch]\n",
        "  return ret\n",
        "\n",
        "def vectorize_dataset(data):\n",
        "  # inputs\n",
        "  enc_inp = str_to_numarray(data[:,1], max_len_input, input_dict)\n",
        "  dec_inp = str_to_numarray(data[:,0], max_len_target, target_dict)\n",
        "  \n",
        "  # targets\n",
        "  dec_tgt = np.pad(dec_inp[:,1:],((0,0),(0,1)))\n",
        "  dec_tgt_onehot = np.zeros((data.shape[0], max_len_target, len_target_vocab), dtype=\"float32\")\n",
        "  for i in range(len_target_vocab): dec_tgt_onehot[:,:,i] = dec_tgt[:,:]==i\n",
        "  \n",
        "  return enc_inp, dec_inp, dec_tgt_onehot\n",
        "\n",
        "enc_inp_train, dec_inp_train, dec_tgt_train_onehot = vectorize_dataset(train_data)\n",
        "enc_inp_val,   dec_inp_val,   dec_tgt_val_onehot   = vectorize_dataset(val_data)\n",
        "enc_inp_test,  dec_inp_test,  dec_tgt_test_onehot  = vectorize_dataset(test_data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3-NFLIXk51NL"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYGzxCwa5asf"
      },
      "source": [
        "## Model Handling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKGB3v7LqKn0"
      },
      "source": [
        "DEFAULT_NETPARAMS = {\n",
        "    \"embed_size\": 16, \n",
        "    \"latent_dim\": 256, \n",
        "    \"enc_layers\": 1, \n",
        "    \"dec_layers\": 1, \n",
        "    \"recurrent_cell\": \"SimpleRNN\",\n",
        "    \"dec_attention\": False,\n",
        "    \"dropout\": 0, \n",
        "    \"beam_size\": 1, \n",
        "    \"enc_state_dep\": \"first\"\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjhsuXPfDS4m"
      },
      "source": [
        "def fresh_training_model(netparams):\n",
        "  # unpack network parameters\n",
        "  embed_size = netparams[\"embed_size\"]\n",
        "  latent_dim = netparams[\"latent_dim\"]\n",
        "  enc_layers = netparams[\"enc_layers\"]\n",
        "  dec_layers = netparams[\"dec_layers\"]\n",
        "  exec(\"rlexec=ks.layers.\"+netparams[\"recurrent_cell\"]); recurrent_cell = locals()[\"rlexec\"]\n",
        "  dec_attention = netparams[\"dec_attention\"]\n",
        "  dropout    = netparams[\"dropout\"]\n",
        "  enc_state_dep = netparams[\"enc_state_dep\"]\n",
        "\n",
        "  # encoder layers\n",
        "  encoder_input = ks.Input(shape=(None,), name=\"encoder_input\")\n",
        "  encoder_embedding = ks.layers.Embedding(len_input_vocab+1, embed_size, mask_zero=True, name=\"encoder_embedding\")\n",
        "  encoder_rnns = [recurrent_cell(latent_dim, return_sequences=True, return_state=True, dropout=dropout, name=\"encoder_rnn_\"+str(i)) for i in range(1,enc_layers+1)]\n",
        "\n",
        "  # encoder feedforward path\n",
        "  encoder_output = encoder_embedding(encoder_input)\n",
        "  for encoder_rnn in encoder_rnns:\n",
        "    encoder_ret = encoder_rnn(encoder_output)\n",
        "    encoder_output, encoder_state = encoder_ret[0], list(encoder_ret[1:])\n",
        "\n",
        "  # decoder layers\n",
        "  decoder_input = ks.Input(shape=(None,), name=\"decoder_input\")\n",
        "  decoder_embedding = ks.layers.Embedding(len_target_vocab+1, embed_size, mask_zero=True, name=\"decoder_embedding\")\n",
        "  decoder_rnns = [recurrent_cell(latent_dim, return_sequences=True, return_state=True, dropout=dropout, name=\"decoder_rnn_\"+str(i)) for i in range(1,dec_layers+1)]\n",
        "  if dec_attention:\n",
        "    decoder_attention = ks.layers.AdditiveAttention(name=\"decoder_attention\")\n",
        "    decoder_concat    = ks.layers.Concatenate(name=\"decoder_concat\")\n",
        "  decoder_dropout = ks.layers.Dropout(dropout, name=\"decoder_dropout\")\n",
        "  decoder_dense = ks.layers.Dense(len_target_vocab, activation=\"softmax\", name=\"decoder_dense\")\n",
        "\n",
        "  # decoder feedforward path\n",
        "  decoder_rnn_out = decoder_embedding(decoder_input)\n",
        "  for i,decoder_rnn in enumerate(decoder_rnns):\n",
        "    if enc_state_dep=='first':\n",
        "      decoder_state_input = encoder_state if i==0 else None\n",
        "    elif enc_state_dep=='all':\n",
        "      decoder_state_input = encoder_state\n",
        "    else:\n",
        "      decoder_state_input = None\n",
        "    decoder_ret = decoder_rnn(decoder_rnn_out, initial_state=decoder_state_input)\n",
        "    decoder_rnn_out = decoder_ret[0]\n",
        "  if dec_attention:\n",
        "    context_vec, attn_weights = decoder_attention([decoder_rnn_out, encoder_output], return_attention_scores=True)\n",
        "    decoder_dense_input = decoder_concat([decoder_rnn_out, context_vec])\n",
        "  else:\n",
        "    decoder_dense_input = decoder_rnn_out\n",
        "  decoder_dense_input = decoder_dropout(decoder_dense_input, training=True)\n",
        "  decoder_output = decoder_dense(decoder_dense_input)\n",
        "\n",
        "  model = ks.Model([encoder_input, decoder_input], decoder_output, name=\"training_model\")\n",
        "  model.netparams = netparams\n",
        "  return model\n",
        "\n",
        "def gen_enc_dec_models(model):\n",
        "  # get layer from name\n",
        "  layer_idxs = dict([(l.name,i) for i,l in enumerate(model.layers)])\n",
        "  layer_from_name = lambda s: model.layers[layer_idxs[s]]\n",
        "  \n",
        "  # unpack network parameters\n",
        "  netparams  = model.netparams\n",
        "  latent_dim = netparams[\"latent_dim\"]\n",
        "  enc_layers = netparams[\"enc_layers\"]\n",
        "  dec_layers = netparams[\"dec_layers\"]\n",
        "  dec_attention = netparams[\"dec_attention\"]\n",
        "  recurrent_cell_name = netparams[\"recurrent_cell\"]\n",
        "\n",
        "  # reconstructing encoder model\n",
        "    # inputs\n",
        "  encoder_model_input = layer_from_name(\"encoder_input\").input\n",
        "    # outputs\n",
        "  encoder_model_ret = layer_from_name(\"encoder_rnn_\"+str(enc_layers)).output\n",
        "  encoder_model_output, encoder_model_state_output = encoder_model_ret[0], list(encoder_model_ret[1:])\n",
        "    # model reconstruction\n",
        "  encoder_model = ks.Model(\n",
        "    encoder_model_input, \n",
        "    [encoder_model_output, encoder_model_state_output], \n",
        "    name=\"encoder_model\"\n",
        "  )\n",
        "\n",
        "  # reconstructing decoder model\n",
        "    # inputs\n",
        "  decoder_model_input  = layer_from_name(\"decoder_input\").input\n",
        "  decoder_model_encoder_output = ks.Input(shape=(max_len_input,latent_dim,), name=\"decoder_encoder_output\")\n",
        "  decoder_model_state_input  = []\n",
        "    # outputs\n",
        "  decoder_model_output = layer_from_name(\"decoder_embedding\")(decoder_model_input)\n",
        "  decoder_model_state_output = []\n",
        "    # model reconstruction\n",
        "  for dec_layer in range(1,dec_layers+1):\n",
        "    decoder_model_state_input.append(\n",
        "        [ks.Input(shape=(latent_dim,), name=\"decoder_state_h_\"+str(dec_layer)), ks.Input(shape=(latent_dim,), name=\"decoder_state_c_\"+str(dec_layer))] \n",
        "        if recurrent_cell_name==\"LSTM\" else [ks.Input(shape=(latent_dim,), name=\"decoder_state_\"+str(dec_layer))]\n",
        "    )\n",
        "    decoder_ret = layer_from_name(\"decoder_rnn_\"+str(dec_layer))(decoder_model_output, initial_state = decoder_model_state_input[-1])\n",
        "    decoder_model_output, decoder_model_state = decoder_ret[0], list(decoder_ret[1:])\n",
        "    decoder_model_state_output.append(decoder_model_state)\n",
        "    dec_layer += 1\n",
        "  if dec_attention:\n",
        "    decoder_model_context_vec, decoder_model_attention_weights = layer_from_name(\"decoder_attention\")([decoder_model_output, decoder_model_encoder_output], return_attention_scores=True)\n",
        "    decoder_model_output = layer_from_name(\"decoder_concat\")([decoder_model_output, decoder_model_context_vec])\n",
        "  decoder_model_output = layer_from_name(\"decoder_dropout\")(decoder_model_output, training=False)\n",
        "  decoder_model_output = layer_from_name(\"decoder_dense\")(decoder_model_output)\n",
        "  if dec_attention:\n",
        "    decoder_model = ks.Model(\n",
        "      [decoder_model_input, decoder_model_encoder_output, decoder_model_state_input], \n",
        "      [decoder_model_output, decoder_model_state_output, decoder_model_attention_weights], \n",
        "      name=\"decoder_model\"\n",
        "    )\n",
        "  else:\n",
        "    decoder_model = ks.Model(\n",
        "      [decoder_model_input, decoder_model_state_input], \n",
        "      [decoder_model_output, decoder_model_state_output], \n",
        "      name=\"decoder_model\"\n",
        "    )\n",
        "\n",
        "  encoder_model.netparams = netparams\n",
        "  decoder_model.netparams = netparams\n",
        "\n",
        "  return encoder_model, decoder_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jUg86VR6CFA"
      },
      "source": [
        "## Decoding Input String"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vdSmTDeI-XB"
      },
      "source": [
        "def decode_sequence(input_seq, models):\n",
        "  # Convert string input to numerical array\n",
        "  encoded_input_seq = str_to_numarray([input_seq], max_len_input, input_dict)\n",
        "\n",
        "  # Unpack testing model and its network parameters\n",
        "  encoder_model, decoder_model = models\n",
        "  netparams = decoder_model.netparams\n",
        "  latent_dim = netparams[\"latent_dim\"]\n",
        "  recurrent_cell_name = netparams[\"recurrent_cell\"]\n",
        "  dec_attention = netparams[\"dec_attention\"]\n",
        "  dec_layers = netparams[\"dec_layers\"]\n",
        "  enc_state_dep = netparams[\"enc_state_dep\"]\n",
        "  \n",
        "  # Run encoder model and create initial state for decoder\n",
        "  encoder_layer_out, encoder_states_out = encoder_model.predict(encoded_input_seq)\n",
        "  default_initial_state = [np.zeros((1,latent_dim))]*(2 if recurrent_cell_name==\"LSTM\" else 1)\n",
        "  if enc_state_dep=='first':\n",
        "    decoder_state = [encoder_states_out] + [default_initial_state]*(dec_layers-1)\n",
        "  elif enc_state_dep=='all':\n",
        "    decoder_state = [encoder_states_out] * dec_layers\n",
        "  else:\n",
        "    decoder_state = [default_initial_state] * dec_layers\n",
        "\n",
        "  # Generate empty target sequence of length 1.\n",
        "  target_seq = np.array(target_dict[STARTCHAR],ndmin=2)\n",
        "\n",
        "  # Sampling loop for a batch of sequences\n",
        "  # (to simplify, here we assume a batch of size 1).\n",
        "  stop_condition = False\n",
        "  decoded_sentence = \"\"\n",
        "  attn_weights_lst = []\n",
        "\n",
        "  while not stop_condition:\n",
        "    if dec_attention:\n",
        "        output_tokens, decoder_state, attn_weights = decoder_model.predict([target_seq, encoder_layer_out, decoder_state])\n",
        "        attn_weights_lst.append(attn_weights)\n",
        "    else:\n",
        "        output_tokens, decoder_state = decoder_model.predict([target_seq, decoder_state])\n",
        "\n",
        "    # Sample a token\n",
        "    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
        "    sampled_char = target_vocab[sampled_token_index]\n",
        "    decoded_sentence += sampled_char\n",
        "\n",
        "    # Exit condition: either hit max length\n",
        "    # or find stop character.\n",
        "    if sampled_char == ENDCHAR or len(decoded_sentence) > max_len_target:\n",
        "        stop_condition = True\n",
        "\n",
        "    # Update the target sequence (of length 1).\n",
        "    target_seq[0,0] = sampled_token_index\n",
        "\n",
        "  if dec_attention:\n",
        "      return decoded_sentence, attn_weights_lst\n",
        "  else:\n",
        "      return decoded_sentence"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TITfjs6n5kh_"
      },
      "source": [
        "# Sample Runs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HR2_cz6vUimT"
      },
      "source": [
        "## Training a model for a particular network configuration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_OEEPxLutm-Q"
      },
      "source": [
        "# initialize training model\n",
        "netparams = DEFAULT_NETPARAMS.copy()\n",
        "netparams.update({\n",
        "  \"embed_size\": 16, \n",
        "  \"latent_dim\": 256, \n",
        "  \"enc_layers\": 3, \n",
        "  \"dec_layers\": 2, \n",
        "  \"recurrent_cell\": \"LSTM\",\n",
        "  \"dec_attention\": True,\n",
        "  \"dropout\": 0.05, \n",
        "  \"beam_size\": 1, \n",
        "  \"enc_state_dep\": \"first\"\n",
        "})\n",
        "training_model = fresh_training_model(netparams) # ks.models.load_model(savedModelPath)\n",
        "training_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ET4ji9GkYz0W"
      },
      "source": [
        "# training parameters\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "# compile training model\n",
        "training_model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Create callbacks\n",
        "wandb=True\n",
        "patience=5\n",
        "\n",
        "callbacks=[ks.callbacks.EarlyStopping(\n",
        "  patience=patience,\n",
        "  restore_best_weights=True\n",
        ")]\n",
        "if wandb:\n",
        "  wandb.init(project=\"Dakshina HI Test 1\")\n",
        "  callbacks.append([wandb.keras.WandbCallback(monitor=\"val_accuracy\")])\n",
        "\n",
        "# train seq2seq model\n",
        "training_model.fit(\n",
        "    [enc_inp_train, dec_inp_train],\n",
        "    dec_tgt_train_onehot,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=( [enc_inp_val, dec_inp_val], dec_tgt_val_onehot ),\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ohl7khBRXUTc"
      },
      "source": [
        "training_model.evaluate(x=[enc_inp_test, dec_inp_test], y=dec_tgt_test_onehot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5skFP9OyVWPQ"
      },
      "source": [
        "training_model.save(\"/content/drive/MyDrive/Sem_8/s2s_samplerun.h5\")\n",
        "json.dump(netparams, open(\"/content/drive/MyDrive/Sem_8/s2s_samplerun.json\",'w'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6NseynqUvH1"
      },
      "source": [
        "## Testing trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHwFkyuoIfd7"
      },
      "source": [
        "use_trained_model = False\n",
        "load_timestamp = \"20210506_215919\"\n",
        "\n",
        "if use_trained_model:\n",
        "  test_model = training_model\n",
        "else:\n",
        "  test_model = ks.models.load_model(\"/content/drive/MyDrive/Sem_8/trained-models/s2s_sweep_\"+load_timestamp+\".h5\")\n",
        "  test_model.netparams = json.load(open(\"/content/drive/MyDrive/Sem_8/trained-models/s2s_sweep_\"+load_timestamp+\".json\",'r'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VrhZZk4i6rB"
      },
      "source": [
        "test_model.evaluate(x=[enc_inp_test, dec_inp_test], y=dec_tgt_test_onehot)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2XkoCqBfiQa"
      },
      "source": [
        "encoder_model, decoder_model = gen_enc_dec_models(test_model)\n",
        "encoder_model.summary()\n",
        "decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QNdOBVzwTYM1"
      },
      "source": [
        "print(decode_sequence(\"rani\", [encoder_model, decoder_model]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z8_vhwvv7W4y"
      },
      "source": [
        "# Training Sweep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Vtz3Qo0Ca7v"
      },
      "source": [
        "sweeplog_path = \"/content/drive/MyDrive/Sem_8/sweep/sweeplog.txt\"\n",
        "savemodel_path = \"/content/drive/MyDrive/Sem_8/sweep/trained-models\"\n",
        "run_sep = '-='*30+'-'\n",
        "\n",
        "!mkdir -p $savemodel_path\n",
        "!touch $sweeplog_path"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gOWMrRtOFF8-"
      },
      "source": [
        "def runWandbSweep():\n",
        "  wandb.init(project=\"dakshina_sweep\")\n",
        "  \n",
        "  tcr_wandb_format     = timestr(\"%b %d '%y %H:%M\")\n",
        "  tcr_savemodel_format = timestr(\"%Y%m%d_%H%M%S\")\n",
        "\n",
        "  cfg = wandb.config\n",
        "  netparams = DEFAULT_NETPARAMS.copy()\n",
        "  netparams.update({\n",
        "    \"embed_size\": cfg.embedding_size, \n",
        "    \"latent_dim\": cfg.hidden_layer_size,\n",
        "    \"enc_layers\": cfg.num_encoder_layers,\n",
        "    \"dec_layers\": cfg.num_decoder_layers,\n",
        "    \"recurrent_cell\": cfg.a1_recurrent_cell,\n",
        "    \"dec_attention\": cfg.decoder_attention,\n",
        "    \"dropout\": cfg.dropout,\n",
        "    \"enc_state_dep\": cfg.encoder_state_dependencies\n",
        "  })\n",
        "  \n",
        "  log_output = \"Sweep run created on \"+tcr_wandb_format+\" (\"+tcr_savemodel_format+\") with following sweep parameters:\\n\"\n",
        "  for i,k in enumerate(netparams):\n",
        "    log_output += str(i+1)+\". \"+k+\" = \"+str(netparams[k])+'\\n'\n",
        "  log_output += \"\\n\\n\"\n",
        "  open(sweeplog_path,'a').write(log_output)\n",
        "  \n",
        "  model = fresh_training_model(netparams)\n",
        "  model.compile(optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  \n",
        "  model.fit(\n",
        "      [enc_inp_train, dec_inp_train],\n",
        "      dec_tgt_train_onehot,\n",
        "      batch_size=cfg.batch_size,\n",
        "      epochs=cfg.epochs,\n",
        "      validation_data=( [enc_inp_val, dec_inp_val], dec_tgt_val_onehot ),\n",
        "      callbacks=[\n",
        "                  ks.callbacks.EarlyStopping(monitor=\"val_loss\", patience=10, restore_best_weights=True)\n",
        "                , wandb.keras.WandbCallback(monitor=\"val_accuracy\")\n",
        "                ]\n",
        "  )\n",
        "\n",
        "  model.save(savemodel_path+\"/s2s_sweep_\"+tcr_savemodel_format+\".h5\")\n",
        "  json.dump(netparams, open(savemodel_path+\"/s2s_sweep_\"+tcr_savemodel_format+\".json\",'w'))\n",
        "  open(sweeplog_path,'a').write(\"Sweep run completed, model saved with timestamp: \"+tcr_savemodel_format+\"\\n\\n\"+run_sep+\"\\n\\n\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71HRcdIeY5uU"
      },
      "source": [
        "wandbSweepCfg = {\n",
        "  \"name\":\"Dakshina Parameter Grid Sweep (xAttention)\", \n",
        "  \"metric\":{\n",
        "    \"name\":\"val_accuracy\",\n",
        "    \"goal\":\"maximize\"\n",
        "  }, \n",
        "  \"method\": \"grid\", \n",
        "  \"parameters\":{\n",
        "    # network parameters\n",
        "    \"embedding_size\": {\"values\":[128, 256]},\n",
        "    \"hidden_layer_size\": {\"values\":[128, 256]},\n",
        "    \"num_encoder_layers\": {\"values\":[1, 2]},\n",
        "    \"num_decoder_layers\": {\"values\":[1]},\n",
        "    \"a1_recurrent_cell\": {\"values\":[\"GRU\", \"LSTM\", \"SimpleRNN\"]},\n",
        "    \"decoder_attention\": {\"values\":[False]},\n",
        "    \"dropout\": {\"values\":[0.2, 0.4]},\n",
        "    \"encoder_state_dependencies\":{\"values\":[\"first\"]},\n",
        "    \n",
        "    # training parameters\n",
        "    \"epochs\": { \"values\":[30] },\n",
        "    \"batch_size\": { \"values\":[32] }\n",
        "  }\n",
        "}\n",
        "\n",
        "open(sweeplog_path,'a').write(run_sep+\"\\n\\nStarted sweep at \"+timestr(\"%H:%M:%S on %b %d, %Y\")+'\\n\\n')\n",
        "\n",
        "sweepId = wandb.sweep(wandbSweepCfg)#\"vasid99/uncategorized/uklnmska\"\n",
        "wandb.agent(sweepId, function = runWandbSweep)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L9C9Owb48Fe9"
      },
      "source": [
        "# Testing with attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GzcKpC8-8JNm"
      },
      "source": [
        "# initialize training model\n",
        "netparams = DEFAULT_NETPARAMS.copy()\n",
        "netparams.update({\n",
        "  \"embed_size\": 64, \n",
        "  \"latent_dim\": 256, \n",
        "  \"enc_layers\": 1, \n",
        "  \"dec_layers\": 1, \n",
        "  \"recurrent_cell\": \"LSTM\",\n",
        "  \"dec_attention\": True,\n",
        "  \"dropout\": 0.2, \n",
        "  \"beam_size\": 1, \n",
        "  \"enc_state_dep\": \"first\"\n",
        "})\n",
        "training_model = fresh_training_model(netparams) # ks.models.load_model(savedModelPath)\n",
        "#training_model.summary()\n",
        "\n",
        "\n",
        "# training parameters\n",
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "# compile training model\n",
        "training_model.compile(\n",
        "    optimizer=\"rmsprop\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "# Create callbacks\n",
        "wandb=False\n",
        "patience=5\n",
        "\n",
        "callbacks=[ks.callbacks.EarlyStopping(\n",
        "  patience=patience,\n",
        "  restore_best_weights=True\n",
        ")]\n",
        "if wandb:\n",
        "  wandb.init(project=\"Dakshina HI Test 1\")\n",
        "  callbacks.append([wandb.keras.WandbCallback(monitor=\"val_accuracy\")])\n",
        "\n",
        "# train seq2seq model\n",
        "training_model.fit(\n",
        "    [enc_inp_train, dec_inp_train],\n",
        "    dec_tgt_train_onehot,\n",
        "    batch_size=batch_size,\n",
        "    epochs=epochs,\n",
        "    validation_data=( [enc_inp_val, dec_inp_val], dec_tgt_val_onehot ),\n",
        "    callbacks=callbacks\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KietThFr_HR6"
      },
      "source": [
        "encoder_model, decoder_model = gen_enc_dec_models(training_model)\n",
        "encoder_model.summary()\n",
        "decoder_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbn-CNvh_RCY"
      },
      "source": [
        "seq_pred, attn_weights = decode_sequence(\"asambhav\", [encoder_model, decoder_model])\n",
        "seq_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HEeIwn_RAlIC"
      },
      "source": [
        "len(attn_weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TdH6B7TQA3ni"
      },
      "source": [
        "len(seq_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szoC3SdOA8_s"
      },
      "source": [
        "attn_weights[0].shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qd3QWyYhByiw"
      },
      "source": [
        "len_input = len('asambhav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hySzdlxHBDH4"
      },
      "source": [
        "attn_weights = np.array([ element[0,0,:len_input] for element in attn_weights ])\n",
        "attn_weights.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UuZM3fMEB_Rq"
      },
      "source": [
        "attn_weights"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U7zq7RpaCc-4"
      },
      "source": [
        "plt.imshow(attn_weights, cmap='hot', interpolation='nearest')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JD7k9jk4LCKZ"
      },
      "source": [
        "# Sweep with attention"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tYRGBlkKL_Y2"
      },
      "source": [
        "wandbSweepCfg = {\n",
        "  \"name\":\"Dakshina Parameter Grid Sweep (wAttention)\", \n",
        "  \"metric\":{\n",
        "    \"name\":\"val_accuracy\",\n",
        "    \"goal\":\"maximize\"\n",
        "  }, \n",
        "  \"method\": \"grid\", \n",
        "  \"parameters\":{\n",
        "    # network parameters\n",
        "    \"embedding_size\": {\"values\":[128, 256]},\n",
        "    \"hidden_layer_size\": {\"values\":[128, 256]},\n",
        "    \"num_encoder_layers\": {\"values\":[1, 2]},\n",
        "    \"num_decoder_layers\": {\"values\":[1]},\n",
        "    \"a1_recurrent_cell\": {\"values\":[\"GRU\", \"LSTM\", \"SimpleRNN\"]},\n",
        "    \"decoder_attention\": {\"values\":[True]},\n",
        "    \"dropout\": {\"values\":[0.2, 0.4]},\n",
        "    \"encoder_state_dependencies\":{\"values\":[\"first\"]},\n",
        "    \n",
        "    # training parameters\n",
        "    \"epochs\": { \"values\":[30] },\n",
        "    \"batch_size\": { \"values\":[32] }\n",
        "  }\n",
        "}\n",
        "\n",
        "open(sweeplog_path,'a').write(run_sep+\"\\n\\nStarted sweep at \"+timestr(\"%H:%M:%S on %b %d, %Y\")+'\\n\\n')\n",
        "\n",
        "sweepId = wandb.sweep(wandbSweepCfg)#\"vasid99/uncategorized/uklnmska\"\n",
        "wandb.agent(sweepId, function = runWandbSweep)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}